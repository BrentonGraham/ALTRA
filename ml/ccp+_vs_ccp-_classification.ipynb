{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1d32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from utils.ml_utils import xy_split, flatten_list, getClfStats\n",
    "from models.RF import RF\n",
    "from models.SVM import SVM\n",
    "from models.XGBoost import XGBoost\n",
    "from models.MLPNN import MLPNN\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896873b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88291294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClfROC(y_true, y_pred, y_score, plotLabel):\n",
    "    '''\n",
    "    Function to evaluate performance of a binary classifier\n",
    "    \n",
    "    Input:\n",
    "        y_true: True values of targets\n",
    "        y_pred: Predicted values of targets (as determined by trained model)\n",
    "        y_score: Target scores (probability estimates of the positive class)\n",
    "        \n",
    "    Output:\n",
    "        ROC curve with AUC score reported\n",
    "    '''\n",
    "\n",
    "    # ROC, AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc = roc_auc_score(y_true, y_score)    \n",
    "    \n",
    "    # ROC Curve\n",
    "    plt.style.use('seaborn')\n",
    "    plt.plot([0, 1], [0, 1], linewidth=1, color='black', linestyle='--')\n",
    "    plt.plot(fpr, tpr, marker='.', label=f'{plotLabel} (AUC = {round(auc, 3)})')\n",
    "    plt.title('ROC Curve', fontsize=16)\n",
    "    plt.xlabel('1 - Specficity (FPR)', fontsize=14)\n",
    "    plt.ylabel('Sensitivity (TPR)', fontsize=14)\n",
    "    plt.legend(loc='lower right')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615033e5",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b632b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv(f\"{os.getcwd()}/data/altra.stool.rel_ab.csv\")\n",
    "    \n",
    "# Split into targets and features\n",
    "x, y = xy_split(df=df, target=\"ccp3\", to_numpy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34f183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate age and sex \n",
    "x_age = x[['age']].to_numpy()\n",
    "x_sex = x[['sex']].to_numpy()\n",
    "x = x[[column for column in x.columns if column not in ['age', 'sex']]].to_numpy()\n",
    "y = y.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96698a",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28ae2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated CV 1:\n",
      "Fold 1 complete\n",
      "Fold 2 complete\n",
      "Fold 3 complete\n",
      "Fold 4 complete\n",
      "Fold 5 complete\n",
      "\n",
      "Repeated CV 2:\n",
      "Fold 1 complete\n",
      "Fold 2 complete\n",
      "Fold 3 complete\n",
      "Fold 4 complete\n",
      "Fold 5 complete\n",
      "\n",
      "Repeated CV 3:\n",
      "Fold 1 complete\n",
      "Fold 2 complete\n",
      "Fold 3 complete\n",
      "Fold 4 complete\n",
      "Fold 5 complete\n",
      "\n",
      "Repeated CV 4:\n",
      "Fold 1 complete\n",
      "Fold 2 complete\n",
      "Fold 3 complete\n",
      "Fold 4 complete\n",
      "Fold 5 complete\n",
      "\n",
      "Repeated CV 5:\n",
      "Fold 1 complete\n",
      "Fold 2 complete\n",
      "Fold 3 complete\n",
      "Fold 4 complete\n",
      "Fold 5 complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input options\n",
    "log_transform = True\n",
    "pca = True\n",
    "age_and_sex = True\n",
    "\n",
    "# Generate seeds to use for each repeated CV run\n",
    "np.random.seed(1)\n",
    "n_repeats = 5\n",
    "seeds = np.random.randint(10000, size=n_repeats)\n",
    "\n",
    "# Empty data frame to store results from each repeat\n",
    "clfStatsDF = pd.DataFrame(\n",
    "    index=['AUC', 'Precision', 'Recall', 'F1'], \n",
    "    columns=[f'Repeat{i}' for i in range(1, n_repeats+1)])\n",
    "\n",
    "# Copy empty df for each model type\n",
    "clfStatsDF_RF = clfStatsDF.copy()\n",
    "clfStatsDF_XGB = clfStatsDF.copy()\n",
    "clfStatsDF_SVM = clfStatsDF.copy()\n",
    "clfStatsDF_MLP = clfStatsDF.copy()\n",
    "\n",
    "# Repeat 5-fold CV n_repeats times\n",
    "for repeat, seed in enumerate(seeds, 1):\n",
    "    print(f'Repeated CV {repeat}:')\n",
    "\n",
    "    # Initialize stratified k-fold cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    # Initialize objects to store results\n",
    "    yTrue = []\n",
    "    yPred_RF,  yProb_RF  = [], []\n",
    "    yPred_XGB, yProb_XGB = [], []\n",
    "    yPred_SVM, yProb_SVM = [], []\n",
    "    yPred_MLP, yProb_MLP = [], []\n",
    "    \n",
    "    # Train and test for each fold\n",
    "    fold = 1\n",
    "    for train_index, test_index in kfold.split(x, y):\n",
    "\n",
    "        # Split data into train/test sets\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Save test labels\n",
    "        yTrue.append(y_test)\n",
    "\n",
    "        # Log-transform data\n",
    "        if log_transform:\n",
    "            x_train = np.log(x_train + 1)\n",
    "            x_test = np.log(x_test + 1)\n",
    "\n",
    "        # PCA reduction\n",
    "        if pca:\n",
    "            pca = PCA(n_components=0.95)\n",
    "            x_train = pca.fit_transform(x_train)\n",
    "            x_test = pca.transform(x_test)\n",
    "\n",
    "        # Normalize data\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train = scaler.fit_transform(x_train) # Train scalar on training set and tranform\n",
    "        x_test = scaler.transform(x_test)       # Transform test set using fit from training set\n",
    "\n",
    "        # Split age and sex into train/test\n",
    "        if age_and_sex: \n",
    "\n",
    "            # Split age and sex into train/test\n",
    "            age_train, age_test = x_age[train_index], x_age[test_index]\n",
    "            sex_train, sex_test = x_sex[train_index], x_sex[test_index]\n",
    "\n",
    "            # Normalize age\n",
    "            scaler = MinMaxScaler()\n",
    "            age_train = scaler.fit_transform(age_train)\n",
    "            age_test = scaler.transform(age_test)\n",
    "\n",
    "            # Rejoin age and sex into the feature set\n",
    "            x_train = np.concatenate((x_train, age_train, sex_train), axis=1)\n",
    "            x_test = np.concatenate((x_test, age_test, sex_test), axis=1)\n",
    "\n",
    "        # Train models and make predictions on test set\n",
    "        ## RF\n",
    "        rf = RF()\n",
    "        rf.train(trainingData=[x_train, y_train])\n",
    "        yPred_RF.append(rf.predict(x=x_test, proba=False))\n",
    "        yProb_RF.append(rf.predict(x=x_test, proba=True))\n",
    "\n",
    "        ## XGBoost\n",
    "        xgb = XGBoost()\n",
    "        xgb.train(trainingData=[x_train, y_train])\n",
    "        yPred_XGB.append(xgb.predict(x=x_test, proba=False))\n",
    "        yProb_XGB.append(xgb.predict(x=x_test, proba=True))\n",
    "\n",
    "        ## SVM\n",
    "        svm = SVM()\n",
    "        svm.train(trainingData=[x_train, y_train])\n",
    "        yPred_SVM.append(svm.predict(x=x_test, proba=False))\n",
    "        yProb_SVM.append(svm.predict(x=x_test, proba=True))\n",
    "\n",
    "        ## MLPNN\n",
    "        mlp = MLPNN(nFeatures=x_train.shape[1])\n",
    "        mlp.trainModel(trainingData=[x_train, y_train])\n",
    "        yPred_MLP.append(mlp.predict(x=x_test, proba=False).detach().numpy())\n",
    "        yProb_MLP.append(mlp.predict(x=x_test, proba=True).detach().numpy())\n",
    "        \n",
    "        # Message\n",
    "        print(f'Fold {fold} complete')\n",
    "        fold += 1\n",
    "\n",
    "    # Concatenate results\n",
    "    yTrue = np.array(flatten_list(yTrue))\n",
    "    yPred_RF,  yProb_RF  = np.array(flatten_list(yPred_RF)),  np.array(flatten_list(yProb_RF))\n",
    "    yPred_XGB, yProb_XGB = np.array(flatten_list(yPred_XGB)), np.array(flatten_list(yProb_XGB))\n",
    "    yPred_SVM, yProb_SVM = np.array(flatten_list(yPred_SVM)), np.array(flatten_list(yProb_SVM))\n",
    "    yPred_MLP = np.array(flatten_list(flatten_list(yPred_MLP))) # Different output format from other models\n",
    "    yProb_MLP = np.array(flatten_list(flatten_list(yProb_MLP)))\n",
    "    \n",
    "    # Calculate performance metrics and store results\n",
    "    clfStatsDF_RF[f'Repeat{repeat}']  = [value for value in getClfStats(yTrue, yPred_RF,  yProb_RF).values()]\n",
    "    clfStatsDF_XGB[f'Repeat{repeat}'] = [value for value in getClfStats(yTrue, yPred_XGB, yProb_XGB).values()]\n",
    "    clfStatsDF_SVM[f'Repeat{repeat}'] = [value for value in getClfStats(yTrue, yPred_SVM, yProb_SVM).values()]\n",
    "    clfStatsDF_MLP[f'Repeat{repeat}'] = [value for value in getClfStats(yTrue, yPred_MLP, yProb_MLP).values()]\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e795f7f",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a02fd",
   "metadata": {},
   "source": [
    "## Metrics by Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50f16603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "           Repeat1  Repeat2  Repeat3  Repeat4  Repeat5\n",
      "AUC          0.779    0.787    0.754    0.775    0.791\n",
      "Precision    0.750    0.714    0.726    0.746    0.710\n",
      "Recall       0.833    0.833    0.833    0.815    0.815\n",
      "F1           0.789    0.769    0.776    0.779    0.759\n",
      "\n",
      "XGBoost\n",
      "           Repeat1  Repeat2  Repeat3  Repeat4  Repeat5\n",
      "AUC          0.706    0.731    0.755    0.727    0.765\n",
      "Precision    0.755    0.755    0.763    0.769    0.788\n",
      "Recall       0.741    0.741    0.833    0.741    0.759\n",
      "F1           0.748    0.748    0.796    0.755    0.774\n",
      "\n",
      "SVM\n",
      "           Repeat1  Repeat2  Repeat3  Repeat4  Repeat5\n",
      "AUC          0.767    0.859    0.829    0.875    0.826\n",
      "Precision    0.783    0.723    0.758    0.833    0.807\n",
      "Recall       0.870    0.870    0.926    0.833    0.852\n",
      "F1           0.825    0.790    0.833    0.833    0.829\n",
      "\n",
      "Multi-Layer Perceptron\n",
      "           Repeat1  Repeat2  Repeat3  Repeat4  Repeat5\n",
      "AUC          0.841    0.867    0.846    0.843    0.856\n",
      "Precision    0.797    0.762    0.774    0.770    0.758\n",
      "Recall       0.870    0.889    0.889    0.870    0.870\n",
      "F1           0.832    0.821    0.828    0.817    0.810\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "print(clfStatsDF_RF)\n",
    "print('\\nXGBoost')\n",
    "print(clfStatsDF_XGB)\n",
    "print('\\nSVM')\n",
    "print(clfStatsDF_SVM)\n",
    "print('\\nMulti-Layer Perceptron')\n",
    "print(clfStatsDF_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795eec12",
   "metadata": {},
   "source": [
    "## All Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a3065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               RF     XGB     SVM     MLP\n",
      "AUC        0.7772  0.7368  0.8312  0.8506\n",
      "Precision  0.7292  0.7660  0.7808  0.7722\n",
      "Recall     0.8258  0.7630  0.8702  0.8776\n",
      "F1         0.7744  0.7642  0.8220  0.8216\n"
     ]
    }
   ],
   "source": [
    "allStatsDF = pd.DataFrame(index=['AUC', 'Precision', 'Recall', 'F1'], columns=['RF', 'XGB', 'SVM', 'MLP'])\n",
    "allStatsDF['RF'] = clfStatsDF_RF.mean(1)\n",
    "allStatsDF['XGB'] = clfStatsDF_XGB.mean(1)\n",
    "allStatsDF['SVM'] = clfStatsDF_SVM.mean(1)\n",
    "allStatsDF['MLP'] = clfStatsDF_MLP.mean(1)\n",
    "print(allStatsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3cd0c",
   "metadata": {},
   "source": [
    "# TO-DO\n",
    "MLP: Consider class weights for loss and involve validation set/epoch-to-epoch performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
